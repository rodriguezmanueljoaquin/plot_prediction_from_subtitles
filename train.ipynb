{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fquesada/Desktop/ITBA/nlp/plot_prediction_from_subtitles/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-06-20 20:45:24.859863: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-20 20:45:24.884812: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-20 20:45:24.885298: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-20 20:45:25.349164: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['imdb_id', 'original_title', 'overview', 'title', 'subtitles', 'subtitles_word_count'],\n",
      "    num_rows: 4261\n",
      "})\n",
      "T5TokenizerFast(name_or_path='t5-small', vocab_size=32100, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>']}, clean_up_tokenization_spaces=True)\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer,\n",
    ")\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "df = pd.read_csv('./dataset/dataset_True_True_True_True_True.csv')\n",
    "\n",
    "movies = Dataset.from_pandas(df)\n",
    "print(movies)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    }
   ],
   "source": [
    "def preprocess(examples):\n",
    "    t5_task_prefix = \"summarize: \" \n",
    "    inputs = [t5_task_prefix + doc for doc in examples[\"subtitles\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=1024, truncation=True)\n",
    "\n",
    "    labels = tokenizer(text_target=examples[\"overview\"], max_length=128, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_subtitles = movies.map(preprocess, batched=True, num_proc=4, remove_columns=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['imdb_id', 'original_title', 'overview', 'title', 'subtitles', 'subtitles_word_count', 'input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 4261\n",
      "})\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['imdb_id', 'original_title', 'overview', 'title', 'subtitles', 'subtitles_word_count', 'input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 42\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['imdb_id', 'original_title', 'overview', 'title', 'subtitles', 'subtitles_word_count', 'input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 4219\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "test_split = 0.99\n",
    "\n",
    "print(tokenized_subtitles)\n",
    "\n",
    "train_test = tokenized_subtitles.train_test_split(shuffle = True, test_size=test_split, seed=1)\n",
    "# test_valid = train_testvalid[\"test\"].train_test_split(shuffle = True, test_size=(test_split/(test_split + val_split)), seed=random_state)\n",
    "\n",
    "tokenized_subtitles = DatasetDict(\n",
    "    train = train_test[\"train\"],\n",
    "    test = train_test[\"test\"],\n",
    ")\n",
    "\n",
    "print(tokenized_subtitles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "metrics = evaluate.load(\"rouge\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    result = metrics.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "\n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataCollatorForSeq2Seq(tokenizer=T5TokenizerFast(name_or_path='t5-small', vocab_size=32100, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>']}, clean_up_tokenization_spaces=True), model=T5ForConditionalGeneration(\n",
      "  (shared): Embedding(32128, 512)\n",
      "  (encoder): T5Stack(\n",
      "    (embed_tokens): Embedding(32128, 512)\n",
      "    (block): ModuleList(\n",
      "      (0): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (relative_attention_bias): Embedding(32, 8)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
      "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1-5): 5 x T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
      "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): T5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (decoder): T5Stack(\n",
      "    (embed_tokens): Embedding(32128, 512)\n",
      "    (block): ModuleList(\n",
      "      (0): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (relative_attention_bias): Embedding(32, 8)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
      "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1-5): 5 x T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
      "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): T5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
      "), padding=True, max_length=None, pad_to_multiple_of=None, label_pad_token_id=-100, return_tensors='pt')\n",
      "Dataset({\n",
      "    features: ['imdb_id', 'original_title', 'overview', 'title', 'subtitles', 'subtitles_word_count', 'input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 42\n",
      "})\n",
      "Dataset({\n",
      "    features: ['imdb_id', 'original_title', 'overview', 'title', 'subtitles', 'subtitles_word_count', 'input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 4219\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(data_collator)\n",
    "\n",
    "print(tokenized_subtitles[\"train\"])\n",
    "print(tokenized_subtitles[\"test\"])\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"movie-overview-predictor\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=6,\n",
    "    per_device_eval_batch_size=6,\n",
    "    weight_decay=0.01,\n",
    "    eval_steps=50,\n",
    "    do_eval=True,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=13,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    "    logging_dir='./logs',\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=50,\n",
    "    save_steps=500,\n",
    "    push_to_hub=False\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_subtitles[\"train\"],\n",
    "    eval_dataset=tokenized_subtitles[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fquesada/Desktop/ITBA/nlp/plot_prediction_from_subtitles/venv/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "  0%|          | 0/91 [00:00<?, ?it/s]You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      " 55%|█████▍    | 50/91 [00:11<00:09,  4.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.902, 'learning_rate': 9.230769230769232e-06, 'epoch': 7.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \n",
      " 55%|█████▍    | 50/91 [03:40<00:09,  4.45it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.573732852935791, 'eval_rouge1': 0.0236, 'eval_rouge2': 0.002, 'eval_rougeL': 0.0216, 'eval_rougeLsum': 0.0216, 'eval_gen_len': 19.0, 'eval_runtime': 208.6182, 'eval_samples_per_second': 20.224, 'eval_steps_per_second': 3.375, 'epoch': 7.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 91/91 [03:49<00:00,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 229.6549, 'train_samples_per_second': 2.377, 'train_steps_per_second': 0.396, 'train_loss': 4.750209431071858, 'epoch': 13.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=91, training_loss=4.750209431071858, metrics={'train_runtime': 229.6549, 'train_samples_per_second': 2.377, 'train_steps_per_second': 0.396, 'train_loss': 4.750209431071858, 'epoch': 13.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Toy Story'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['title'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"movie-overview-predictor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[21603,    10,  4940,   269,   921,     3,    55,  4372,    95,     3,\n",
      "            55,  4940,   269,   921,     3,    55,  4372,    95,     3,    55,\n",
      "          4940,   269,   921,     3,    55,  4372,    95,     3,    55, 13112,\n",
      "           888,     3,    55, 13112,   888,     3,    55, 13112,   888,     3,\n",
      "            55,  6364,  1346,     3,    55,  6364,  1346,     3,    55,  6364,\n",
      "          1346,     3,    55,     3,    32,    32,   107,  3534,    32,  3534,\n",
      "            32,     3,    55,   540,   540,   540,     3,    55, 17387,    53,\n",
      "             3,    32,    32,   107,  3534,    32,  3534,    32,     3,    55,\n",
      "           540,   540,   540,     3,    55, 17387,    53,     3,    32,    32,\n",
      "           107,  3534,    32,  3534,    32,     3,    55,   540,   540,   540,\n",
      "             3,    55, 17387,    53,  1190,    34,     3,    55,  1190,  1243,\n",
      "           625, 14741,     3,    55,  1190,    34,     3,    55,  1190,  1243,\n",
      "           625, 14741,     3,    55,  1190,    34,     3,    55,  1190,  1243,\n",
      "           625, 14741,     3,    55,  4354,  3005,   158,    15,   102, 15184,\n",
      "           129,   661,   147,     3,    55,  4354,  3005,   158,    15,   102,\n",
      "         15184,   129,   661,   147,     3,    55,  4354,  3005,   158,    15,\n",
      "           102, 15184,   129,   661,   147,     3,    55,   199,     3,    55,\n",
      "          4698,     9,     3,    55,   199,     3,    76,     3,    55,   199,\n",
      "             3,    55,  4698,     9,     3,    55,   199,     3,    76,     3,\n",
      "            55,   199,     3,    55,  4698,     9,     3,    55,   199,     3,\n",
      "            76,     3,    55,     3,    32,   107, 15184,     3,    55, 10843,\n",
      "           424,     3,    55,     3,    32,   107, 15184,     3,    55, 10843,\n",
      "           424,     3,    55,     3,    32,   107, 15184,     3,    55, 10843,\n",
      "           424,     3,    55,  2249,  1367,  1535,  5796,     3,    55,  2249,\n",
      "          1367,  1535,  5796,     3,    55,  2249,  1367,  1535,  5796,     3,\n",
      "            55,     3,    32,   107,   150,     3,    55,   255, 17048,  1679,\n",
      "            63,     3,    55,     3,    32,   107,   150,     3,    55,   255,\n",
      "         17048,  1679,    63,     3,    55,     3,    32,   107,   150,     3,\n",
      "            55,   255, 17048,  1679,    63,     3,    55,  1190,    80,  1580,\n",
      "            26,  1207,    17,  1190,    80,  1580,    26,  1207,    17,  1190,\n",
      "            80,  1580,    26,  1207,    17,   103,   107,     3,    55,   214,\n",
      "           103,   107,     3,    55,   214,   103,   107,     3,    55,   214,\n",
      "           352,   369, 19965,   352,   369, 19965,   352,   369, 19965,  1586,\n",
      "           255, 17048,     3,    55,  1586,   255, 17048,     3,    55,  1586,\n",
      "           255, 17048,     3,    55,  1940,  3211,  1782,  1192,  2054,  1057,\n",
      "          1940,  3211,  1782,  1192,  2054,  1057,  1940,  3211,  1782,  1192,\n",
      "          2054,  1057,   168,  1940, 21677,     3,  1544,     7,  2054,  1057,\n",
      "          1782,   168,  1940, 21677,     3,  1544,     7,  2054,  1057,  1782,\n",
      "           168,  1940, 21677,     3,  1544,     7,  2054,  1057,  1782,  1604,\n",
      "           697,     3,    63,    23,   855,     3,    63,    23,   855,     3,\n",
      "            63,    23,   855,     3,    63,    23,   855,     3,    55,  1604,\n",
      "           697,     3,    63,    23,   855,     3,    63,    23,   855,     3,\n",
      "            63,    23,   855,     3,    63,    23,   855,     3,    55,  1604,\n",
      "           697,     3,    63,    23,   855,     3,    63,    23,   855,     3,\n",
      "            63,    23,   855,     3,    63,    23,   855,     3,    55,   352,\n",
      "         11796,  1207,    17,     3,    55,   352, 11796,  1207,    17,     3,\n",
      "            55,   352, 11796,  1207,    17,     3,    55,   497, 23281,  2512,\n",
      "             3,  4748,    52,    12,    17,   497, 23281,  2512,     3,  4748,\n",
      "            52,    12,    17,   497, 23281,  2512,     3,  4748,    52,    12,\n",
      "            17,     3,   122,    23, 20227,  2787,   120,     3,   122,    23,\n",
      "         20227,  2787,   120,     3,   122,    23, 20227,  2787,   120, 20692,\n",
      "         20692,     1]], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'kissing ooh hoo hoo ho'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "subtitle = df['subtitles'][0]\n",
    "text = \"summarize: \" + subtitle\n",
    "inputs = tokenizer.encode(text, return_tensors=\"pt\", truncation=True).to(\"cuda\")\n",
    "print(inputs)\n",
    "outputs = model.generate(inputs, do_sample=False, num_beams=3, max_length=13)\n",
    "tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
